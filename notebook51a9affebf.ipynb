{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d30634",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-17T16:39:48.322316Z",
     "iopub.status.busy": "2023-08-17T16:39:48.321916Z",
     "iopub.status.idle": "2023-08-17T16:39:50.174078Z",
     "shell.execute_reply": "2023-08-17T16:39:50.172633Z"
    },
    "papermill": {
     "duration": 1.861692,
     "end_time": "2023-08-17T16:39:50.177451",
     "exception": false,
     "start_time": "2023-08-17T16:39:48.315759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'alpha_mix_active_learning'...\r\n",
      "remote: Enumerating objects: 84, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (48/48), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (38/38), done.\u001b[K\r\n",
      "remote: Total 84 (delta 30), reused 10 (delta 10), pack-reused 36\u001b[K\r\n",
      "Unpacking objects: 100% (84/84), 534.58 KiB | 5.51 MiB/s, done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/TheSolY/alpha_mix_active_learning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bbb5042",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T16:39:50.187465Z",
     "iopub.status.busy": "2023-08-17T16:39:50.187007Z",
     "iopub.status.idle": "2023-08-17T16:39:51.282451Z",
     "shell.execute_reply": "2023-08-17T16:39:51.281083Z"
    },
    "papermill": {
     "duration": 1.103507,
     "end_time": "2023-08-17T16:39:51.285243",
     "exception": false,
     "start_time": "2023-08-17T16:39:50.181736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any parent up to mount point /kaggle)\r\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\r\n"
     ]
    }
   ],
   "source": [
    "! git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2182465c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T16:39:51.295992Z",
     "iopub.status.busy": "2023-08-17T16:39:51.295149Z",
     "iopub.status.idle": "2023-08-17T16:39:51.300155Z",
     "shell.execute_reply": "2023-08-17T16:39:51.299282Z"
    },
    "papermill": {
     "duration": 0.013141,
     "end_time": "2023-08-17T16:39:51.302430",
     "exception": false,
     "start_time": "2023-08-17T16:39:51.289289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('alpha_mix_active_learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78c146a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T16:39:51.312789Z",
     "iopub.status.busy": "2023-08-17T16:39:51.311997Z",
     "iopub.status.idle": "2023-08-17T16:40:25.040015Z",
     "shell.execute_reply": "2023-08-17T16:40:25.038800Z"
    },
    "papermill": {
     "duration": 33.736234,
     "end_time": "2023-08-17T16:40:25.042727",
     "exception": false,
     "start_time": "2023-08-17T16:39:51.306493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1+cpu)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.23.5)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\r\n",
      "Requirement already satisfied: torch==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.0.0+cpu)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (4.6.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.0->torchvision) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.0->torchvision) (1.3.0)\r\n",
      "Collecting openml\r\n",
      "  Downloading openml-0.14.1.tar.gz (131 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25hCollecting liac-arff>=2.4.0 (from openml)\r\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hCollecting xmltodict (from openml)\r\n",
      "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from openml) (2.31.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /opt/conda/lib/python3.10/site-packages (from openml) (1.2.2)\r\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from openml) (2.8.2)\r\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from openml) (1.5.3)\r\n",
      "Requirement already satisfied: scipy>=0.13.3 in /opt/conda/lib/python3.10/site-packages (from openml) (1.11.1)\r\n",
      "Requirement already satisfied: numpy>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from openml) (1.23.5)\r\n",
      "Collecting minio (from openml)\r\n",
      "  Downloading minio-7.1.15-py3-none-any.whl (77 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from openml) (9.0.0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->openml) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil->openml) (1.16.0)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.18->openml) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.18->openml) (3.1.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from minio->openml) (2023.5.7)\r\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from minio->openml) (1.26.15)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->openml) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->openml) (3.4)\r\n",
      "Building wheels for collected packages: openml, liac-arff\r\n",
      "  Building wheel for openml (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for openml: filename=openml-0.14.1-py3-none-any.whl size=146945 sha256=ae23838057ab14a7489350888cb9d1272908d8d447d6f33246a9ac95e8417ae0\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/75/bc/fd/739778254a2881ef96b139d0aaf60c6d4f9130bb1459b48f10\r\n",
      "  Building wheel for liac-arff (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11730 sha256=b20e16f49804acabc9d7ee8ecadf8dc9fe676cb486e311f1f3ce2a7b5b674d6d\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\r\n",
      "Successfully built openml liac-arff\r\n",
      "Installing collected packages: xmltodict, minio, liac-arff, openml\r\n",
      "Successfully installed liac-arff-2.5.0 minio-7.1.15 openml-0.14.1 xmltodict-0.13.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision\n",
    "!pip install openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ecc841",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.006592,
     "end_time": "2023-08-17T16:40:25.056218",
     "exception": false,
     "start_time": "2023-08-17T16:40:25.049626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eb944a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T16:40:25.071960Z",
     "iopub.status.busy": "2023-08-17T16:40:25.071482Z",
     "iopub.status.idle": "2023-08-17T18:39:23.183025Z",
     "shell.execute_reply": "2023-08-17T18:39:23.180327Z"
    },
    "papermill": {
     "duration": 7138.123772,
     "end_time": "2023-08-17T18:39:23.186811",
     "exception": false,
     "start_time": "2023-08-17T16:40:25.063039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\r\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\r\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\r\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/CIFAR10/cifar-10-python.tar.gz\r\n",
      "100%|███████████████████████| 170498071/170498071 [00:04<00:00, 34125417.13it/s]\r\n",
      "Extracting data/CIFAR10/cifar-10-python.tar.gz to data/CIFAR10\r\n",
      "Files already downloaded and verified\r\n",
      "number of labeled pool: 5000\r\n",
      "number of unlabeled pool: 45000\r\n",
      "number of validation pool: 0\r\n",
      "number of testing pool: 10000\r\n",
      "Using cpu device.\r\n",
      "VGGClassifier(\r\n",
      "  (vgg): VGG(\r\n",
      "    (features): Sequential(\r\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      (1): ReLU(inplace=True)\r\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      (3): ReLU(inplace=True)\r\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\r\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      (6): ReLU(inplace=True)\r\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      (8): ReLU(inplace=True)\r\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\r\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      (11): ReLU(inplace=True)\r\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      (13): ReLU(inplace=True)\r\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      (15): ReLU(inplace=True)\r\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\r\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      (18): ReLU(inplace=True)\r\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      (20): ReLU(inplace=True)\r\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      (22): ReLU(inplace=True)\r\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\r\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      (25): ReLU(inplace=True)\r\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      (27): ReLU(inplace=True)\r\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      (29): ReLU(inplace=True)\r\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\r\n",
      "    )\r\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\r\n",
      "    (classifier): Sequential(\r\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\r\n",
      "      (1): ReLU(inplace=True)\r\n",
      "      (2): Dropout(p=0.5, inplace=False)\r\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\r\n",
      "      (4): ReLU(inplace=True)\r\n",
      "      (5): Dropout(p=0.5, inplace=False)\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (features): Sequential(\r\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (1): ReLU(inplace=True)\r\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (3): ReLU(inplace=True)\r\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\r\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (6): ReLU(inplace=True)\r\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (8): ReLU(inplace=True)\r\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\r\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (11): ReLU(inplace=True)\r\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (13): ReLU(inplace=True)\r\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (15): ReLU(inplace=True)\r\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\r\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (18): ReLU(inplace=True)\r\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (20): ReLU(inplace=True)\r\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (22): ReLU(inplace=True)\r\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\r\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (25): ReLU(inplace=True)\r\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (27): ReLU(inplace=True)\r\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (29): ReLU(inplace=True)\r\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\r\n",
      "  )\r\n",
      "  (hidden_layers): Sequential(\r\n",
      "    (0): Linear(in_features=4096, out_features=256, bias=True)\r\n",
      "  )\r\n",
      "  (classifier): Sequential(\r\n",
      "    (0): Linear(in_features=256, out_features=10, bias=True)\r\n",
      "  )\r\n",
      ")\r\n",
      "CIFAR10\r\n",
      "SEED 1\r\n",
      "AlphaMixSampling\r\n",
      "Adam optimizer...\r\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\r\n",
      "  warnings.warn(_create_warning_msg(\r\n",
      "Training started...\r\n",
      "100%|████████████████████████████████████████| 20/20 [1:34:03<00:00, 282.19s/it]\r\n",
      "Round 0\r\n",
      "testing accuracy 0.1\r\n",
      "Round 1\r\n",
      "query budget: 5000\r\n",
      "With alpha_cap set to 0.031250, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.062500, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.093750, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.125000, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.156250, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.187500, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.218750, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.250000, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.281250, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.312500, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.343750, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.375000, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.406250, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.437500, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.468750, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.500000, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.531250, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.562500, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.593750, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.625000, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.656250, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.687500, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.718750, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.750000, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.781250, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.812500, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.843750, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.875000, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.906250, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.937500, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 0.968750, number of inconsistencies: 0\r\n",
      "With alpha_cap set to 1.000000, number of inconsistencies: 0\r\n",
      "picked 5000 samples from RandomSampling.\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/alpha_mix_active_learning/main.py\", line 778, in <module>\r\n",
      "    supervised_learning(args)\r\n",
      "  File \"/kaggle/working/alpha_mix_active_learning/main.py\", line 386, in supervised_learning\r\n",
      "    al_train(args, train_args, train_params, args.strategy)\r\n",
      "  File \"/kaggle/working/alpha_mix_active_learning/main.py\", line 414, in al_train\r\n",
      "    al_train_sub_experiment(args, train_args, train_params, strategy_name, general_path, seed)\r\n",
      "  File \"/kaggle/working/alpha_mix_active_learning/main.py\", line 589, in al_train_sub_experiment\r\n",
      "    q_idxs, embeddings, preds, probs, u_idxs, candidate_idxs = strategy.query(budget)\r\n",
      "  File \"/kaggle/working/alpha_mix_active_learning/query_strategies/alpha_mix_sampling.py\", line 95, in query\r\n",
      "    return np.array(selected_idxs), ulb_embedding, pred_1, ulb_probs, u_selected_idxs, idxs_unlabeled[candidate]\r\n",
      "UnboundLocalError: local variable 'u_selected_idxs' referenced before assignment\r\n"
     ]
    }
   ],
   "source": [
    "!python main.py --data_name CIFAR10 --data_dir data --log_dir /kaggle/working/data/cifar-10-batches-py --n_init_lb 5000 --n_query 5000 --n_round 9 --learning_rate 0.001 --n_epoch 20 --model vgg --strategy AlphaMixSampling --alpha_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cdf1e1",
   "metadata": {
    "papermill": {
     "duration": 0.01713,
     "end_time": "2023-08-17T18:39:23.221434",
     "exception": false,
     "start_time": "2023-08-17T18:39:23.204304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7187.460042,
   "end_time": "2023-08-17T18:39:24.589471",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-17T16:39:37.129429",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
